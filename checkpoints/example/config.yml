MODE: 2             # 1: train, 2: test, 3: eval
MODEL: 3            # 1: edge model, 2: inpaint model, 3: edge-inpaint model
MASK: 6             # 0: no mask, 1: random block, 2: center mask, 3: external, 4: 50% external, 50% random block, 5: (50% no mask, 25% ramdom block, 25% external) 6: external non-random
SEED: 10            # random seed
GPU: [0]            # list of gpu ids
AUGMENTATION_TRAIN: 0 # 1: use augmentation to train landmark predictor  0:not use
LANDMARK_POINTS: 68 # 68 for celeba, celeba-hq and 300w, 98 for wflw

TRAIN_INPAINT_IMAGE_FLIST: 
VAL_INPAINT_IMAGE_FLIST: 
TEST_INPAINT_IMAGE_FLIST: ./datasets/example_images.flist

TRAIN_INPAINT_LANDMARK_FLIST: 
VAL_INPAINT_LANDMARK_FLIST: 
TEST_INPAINT_LANDMARK_FLIST: 

TRAIN_MASK_FLIST: 
VAL_MASK_FLIST: 
TEST_MASK_FLIST: ./datasets/example_masks.flist

TRAIN_LANDMARK_LANDMARK_FLIST: 
TEST_LANDMARK_LANDMARK_FLIST:
TRAIN_LANDMARK_IMAGE_FLIST: 
TEST_LANDMARK_IMAGE_FLIST: 

LR: 0.0001                    # learning rate
D2G_LR: 0.1                   # discriminator/generator learning rate ratio
BETA1: 0.0                    # adam optimizer beta1
BETA2: 0.9                    # adam optimizer beta2
BATCH_SIZE: 1                 # input batch size for training
INPUT_SIZE: 256               # input image size for training 0 for original size
MAX_ITERS: 1300000                # maximum number of iterations to train the model


L1_LOSS_WEIGHT: 1             # l1 loss weight
STYLE_LOSS_WEIGHT: 250        # style loss weight
CONTENT_LOSS_WEIGHT: 0.1      # perceptual loss weight
INPAINT_ADV_LOSS_WEIGHT: 0.01 # adversarial loss weight
TV_LOSS_WEIGHT: 0.1           # total variation loss weight

GAN_LOSS: lsgan               # nsgan | lsgan | hinge
GAN_POOL_SIZE: 0              # fake images pool size

SAVE_INTERVAL: 1000           # how many iterations to wait before saving model (0: never)
SAMPLE_INTERVAL: 10         # how many iterations to wait before sampling (0: never)
SAMPLE_SIZE: 2               # number of images to sample
EVAL_INTERVAL: 0              # how many iterations to wait before model evaluation (0: never)
LOG_INTERVAL: 100              # how many iterations to wait before logging training status (0: never)
